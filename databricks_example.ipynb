{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Petrinex Data Loader - Databricks Example\n",
        "\n",
        "Load Alberta Petrinex data (Volumetrics, NGL) using the unified PetrinexClient.\n",
        "\n",
        "**Features:**\n",
        "- Memory efficient incremental loading\n",
        "- Unity Catalog compatible (no `ANY FILE` privilege needed)\n",
        "- Handles ZIP extraction, encoding, malformed rows automatically\n",
        "- Progress tracking with row counts\n",
        "\n",
        "| Data Type | Description |\n",
        "|-----------|-------------|\n",
        "| `Vol` | Conventional Volumetrics (oil & gas production) |\n",
        "| `NGL` | NGL and Marketable Gas Volumes |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install directly from GitHub\n",
        "%pip install git+https://github.com/guanjieshen/petrinex-python-api.git\n",
        "\n",
        "# Or install from a specific branch\n",
        "# %pip install git+https://github.com/guanjieshen/petrinex-python-api.git@feature/ngl-gas-support\n",
        "\n",
        "from petrinex import PetrinexClient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create client for Volumetrics data\n",
        "client = PetrinexClient(spark=spark, jurisdiction=\"AB\", data_type=\"Vol\")\n",
        "\n",
        "print(\"✓ Client initialized\")\n",
        "print(f\"  Data type: {client.data_type}\")\n",
        "print(f\"  Jurisdiction: {client.jurisdiction}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n",
        "\n",
        "Date options:\n",
        "- `updated_after=\"2025-12-01\"` → files updated AFTER this date (incremental)\n",
        "- `from_date=\"2021-01-01\"` → ALL data from this production month onwards\n",
        "- `end_date=\"2023-12-31\"` → optional end date (use with `from_date` for date ranges)\n",
        "\n",
        "For large loads (20+ files), use `uc_table` to write directly to Delta table:\n",
        "- Avoids memory issues and Spark Connect timeouts\n",
        "- Each file written immediately (no accumulation)\n",
        "- Safety: Only appends to tables created by this library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard load (good for small data - under 20 files)\n",
        "df = client.read_spark_df(updated_after=\"2025-12-01\")\n",
        "\n",
        "# For large loads, write directly to Unity Catalog table (recommended for 20+ files)\n",
        "# Creates table if doesn't exist, validates & appends if it does\n",
        "# df = client.read_spark_df(\n",
        "#     from_date=\"2020-01-01\",\n",
        "#     uc_table=\"main.petrinex.volumetrics\"\n",
        "# )\n",
        "\n",
        "# To replace existing data, truncate first:\n",
        "# spark.sql(\"TRUNCATE TABLE main.petrinex.volumetrics\")\n",
        "# df = client.read_spark_df(from_date=\"2020-01-01\", uc_table=\"main.petrinex.volumetrics\")\n",
        "\n",
        "print(f\"\n",
        "✅ Loaded {df.count():,} rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show schema\n",
        "df.printSchema()\n",
        "\n",
        "# Show sample data\n",
        "display(df.limit(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Download Files to Local Directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Petrinex files to local directory (e.g., for archival or offline analysis)\n",
        "# Files are extracted from ZIP and saved as CSVs in subdirectories by production month\n",
        "# Example: /dbfs/petrinex_data/2025-12/Vol_2025-12.csv\n",
        "# Uncomment to download:\n",
        "\n",
        "# paths = client.download_files(\n",
        "#     output_dir=\"/dbfs/petrinex_data\",  # Use /dbfs/ prefix for Databricks DBFS\n",
        "#     updated_after=\"2025-12-01\"\n",
        "# )\n",
        "# print(f\"✓ Downloaded {len(paths)} file(s)\")\n",
        "#\n",
        "# # Example: download historical range\n",
        "# # paths = client.download_files(\n",
        "# #     output_dir=\"/dbfs/petrinex_data\",\n",
        "# #     from_date=\"2021-01-01\",\n",
        "# #     end_date=\"2023-12-31\"\n",
        "# # )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Load NGL Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to load NGL and Marketable Gas data:\n",
        "\n",
        "# ngl_client = PetrinexClient(spark=spark, data_type=\"NGL\")\n",
        "# ngl_df = ngl_client.read_spark_df(updated_after=\"2025-12-01\")\n",
        "# print(f\"\n",
        "✅ NGL data: {ngl_df.count():,} rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Save to Delta Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to save to Delta:\n",
        "\n",
        "# df.write.format(\"delta\") \\\n",
        "#   .mode(\"overwrite\") \\\n",
        "#   .saveAsTable(\"main.petrinex.volumetrics\")\n",
        "# \n",
        "# print(\"✓ Saved to Delta table\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
