{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Petrinex Volumetrics - Load and Display\n",
        "\n",
        "Load Alberta volumetric data from Petrinex into Spark DataFrames.\n",
        "\n",
        "**Features:** Unity Catalog compatible • Direct repo import • Auto ZIP extraction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
        "sys.path.insert(0, os.path.dirname(notebook_path))\n",
        "\n",
        "from petrinex import PetrinexVolumetricsClient\n",
        "from pyspark.sql import functions as F\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "client = PetrinexVolumetricsClient(spark=spark, jurisdiction=\"AB\", file_format=\"CSV\")\n",
        "print(\"✓ Ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List Files (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cutoff = (datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
        "files = client.list_updated_after(cutoff)\n",
        "print(f\"Found {len(files)} files updated after {cutoff}\")\n",
        "[print(f\"{f.production_month} | {f.updated_ts}\") for f in files[:10]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = client.read_updated_after_as_spark_df_via_pandas(\n",
        "    \"2026-01-01\",  # Change date as needed\n",
        "    pandas_read_kwargs={\"dtype\": str, \"encoding\": \"latin1\"}\n",
        ")\n",
        "df.cache()\n",
        "print(f\"✓ Loaded {df.count():,} rows × {len(df.columns)} columns\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(df.limit(100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(df.groupBy(\"production_month\").agg(F.count(\"*\").alias(\"records\")).orderBy(\"production_month\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save to Delta (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to save:\n",
        "# df.withColumn(\"year\", F.substring(\"production_month\", 1, 4)) \\\n",
        "#   .withColumn(\"month\", F.substring(\"production_month\", 6, 2)) \\\n",
        "#   .write.format(\"delta\").mode(\"overwrite\") \\\n",
        "#   .partitionBy(\"year\", \"month\") \\\n",
        "#   .saveAsTable(\"main.petrinex.volumetrics_raw\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
